---
title: "Predition"
author: "Luis Castillo"
date: "29/8/2020"
output: html_document
---

#Data Loading 

library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(lattice)
library(ggplot2)
library(e1071)
library(gbm)
set.seed(123456)

testing <- read.csv("~/Desktop/data sciences/curso 08/pml-testing.csv",
                    na.strings=c("NA","#DIV/0!",""))
training <- read.csv("~/Desktop/data sciences/curso 08/pml-training.csv",
                     na.strings=c("NA","#DIV/0!",""))

# create a partition using caret with the training dataset on 70,30 ratio

inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]
dim(TrainSet)
dim(TestSet)


# remove variables with Nearly Zero Variance

NZV <- nearZeroVar(TrainSet)
TrainSet <- TrainSet[, -NZV]
TestSet  <- TestSet[, -NZV]
dim(TestSet)
dim(TrainSet)
dim(TrainSet)

# remove variables that are mostly NA

AllNA    <- sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet <- TrainSet[, AllNA==FALSE]
TestSet  <- TestSet[, AllNA==FALSE]
dim(TestSet)

# remove identification only variables (columns 1 to 5)
TrainSet <- TrainSet [, -(1:5)]
TestSet  <- TestSet[, -(1:5)]
dim(TrainSet)

# model fit 01 Random Forests
set.seed(123456)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modFitRandForest <- train(classe ~ ., data=TrainSet, method="rf",
                          trControl=controlRF)
modFitRandForest

## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
## 
##         OOB estimate of  error rate: 0.28%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3905    0    0    0    1 0.0002560164
## B    6 2647    4    1    0 0.0041384500
## C    0    6 2389    1    0 0.0029215359
## D    0    0   11 2240    1 0.0053285968
## E    0    1    0    7 2517 0.0031683168


# prediction on Test dataset
set.seed(123456)
predictRandForest <- predict(modFitRandForest, newdata=TestSet)
confMatRandForest <- confusionMatrix(predictRandForest, TestSet$classe)
confMatRandForest

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673   10    0    0    0
##          B    1 1128    6    0    0
##          C    0    1 1020    1    0
##          D    0    0    0  963    0
##          E    0    0    0    0 1082
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9968         
##                  95% CI : (0.995, 0.9981)
##     No Information Rate : 0.2845         
##     P-Value [Acc > NIR] : < 2.2e-16      
##                                          
##                   Kappa : 0.9959         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   0.9903   0.9942   0.9990   1.0000
## Specificity            0.9976   0.9985   0.9996   1.0000   1.0000
## Pos Pred Value         0.9941   0.9938   0.9980   1.0000   1.0000
## Neg Pred Value         0.9998   0.9977   0.9988   0.9998   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2843   0.1917   0.1733   0.1636   0.1839
## Detection Prevalence   0.2860   0.1929   0.1737   0.1636   0.1839
## Balanced Accuracy      0.9985   0.9944   0.9969   0.9995   1.0000


# model fit 02 Decision Tree
set.seed(123456)
predictDecTree <- predict(modFitDecTree, newdata=TestSet, type="class")
confMatDecTree <- confusionMatrix(predictDecTree, TestSet$classe)
confMatDecTree

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1441  107    2   15    5
##          B  156  880   73   80   56
##          C    0   48  848   29    0
##          D   64   58   98  761   72
##          E   13   46    5   79  949
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8291          
##                  95% CI : (0.8192, 0.8386)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.7843          
##  Mcnemar's Test P-Value : < 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8608   0.7726   0.8265   0.7894   0.8771
## Specificity            0.9694   0.9231   0.9842   0.9407   0.9702
## Pos Pred Value         0.9178   0.7068   0.9168   0.7227   0.8690
## Neg Pred Value         0.9460   0.9442   0.9641   0.9580   0.9723
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2449   0.1495   0.1441   0.1293   0.1613
## Detection Prevalence   0.2668   0.2116   0.1572   0.1789   0.1856
## Balanced Accuracy      0.9151   0.8479   0.9053   0.8650   0.9237


# model fit 03 Generalized Boosted Model (GBM)
set.seed(123456)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGBM  <- train(classe ~ ., data=TrainSet, method = "gbm",
                    trControl = controlGBM, verbose = FALSE)
modFitGBM$finalModel

fitControl <- trainControl(method="repeatedcv", number=5, repeats=1)
model2 <- train(classe ~., data=TrainSet, method="gbm", trControl=fitControl, 
                verbose=FALSE)

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674   10    0    0    0
##          B    0 1119   11    7    6
##          C    0    7 1010    8    2
##          D    0    3    4  949    9
##          E    0    0    1    0 1065
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9884         
##                  95% CI : (0.9854, 0.991)
##     No Information Rate : 0.2845         
##     P-Value [Acc > NIR] : < 2.2e-16      
##                                          
##                   Kappa : 0.9854         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9824   0.9844   0.9844   0.9843
## Specificity            0.9976   0.9949   0.9965   0.9967   0.9998
## Pos Pred Value         0.9941   0.9790   0.9834   0.9834   0.9991
## Neg Pred Value         1.0000   0.9958   0.9967   0.9970   0.9965
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2845   0.1901   0.1716   0.1613   0.1810
## Detection Prevalence   0.2862   0.1942   0.1745   0.1640   0.1811
## Balanced Accuracy      0.9988   0.9887   0.9905   0.9906   0.9920

#Applying the selected Model to the Test Data

predictTEST <- predict(modFitRandForest, newdata=testing)
predictTEST

##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
